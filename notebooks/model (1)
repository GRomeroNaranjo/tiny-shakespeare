{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyP2i4dy0St23L8SX1h2v6q+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9OzB-Xg680K0","executionInfo":{"status":"ok","timestamp":1744902736422,"user_tz":-120,"elapsed":4045,"user":{"displayName":"guillem romero","userId":"01648526312521908562"}},"outputId":"c71e2fbb-cc80-40d0-b209-7b5043bd7798"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from dataclasses import dataclass\n","import os\n","os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n","!pip install tiktoken\n","\n","from google.colab import drive\n","import sys\n","\n","drive.mount('/content/drive')\n","sys.path.append(\"/content/drive/MyDrive/Tiny-Shakespeare\")\n","\n","from minbpe.basic import BasicTokenizer\n","\n","# Load your tokenizer\n","tokenizer = BasicTokenizer()\n","tokenizer.load(\"/content/drive/MyDrive/Tiny-Shakespeare/tokenizer_saved.model\")\n","\n","\n","@dataclass\n","class Config:\n","    n_embed: int = 384\n","    n_head: int = 8\n","    n_layer: int = 12\n","    block_size: int = 256\n","    dropout: float = 0.2\n","    batch_size: int = 64\n","    vocab_size: int = len(tokenizer.vocab)\n","    head_size: int = 384 // 8\n","\n","class GPT_Model(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","        self.config = config\n","        self.embeddings = nn.Embedding(config.vocab_size, config.n_embed)\n","        self.pos_embeddings = nn.Embedding(config.block_size, config.n_embed)\n","\n","        self.blocks = nn.ModuleList([Block(config) for _ in range(config.n_layer)])\n","        self.layer_norm = nn.LayerNorm(config.n_embed)\n","        self.linear_output = nn.Linear(config.n_embed, config.vocab_size)\n","\n","        self.to(device)\n","\n","    def forward(self, x, targets):\n","        embed = self.embeddings(x)\n","        B, T = x.shape\n","        positions = torch.arange(T, device=x.device).unsqueeze(0).expand(B, T)\n","        pos_embed = self.pos_embeddings(positions)\n","\n","        x = embed + pos_embed\n","        for layer in self.blocks:\n","            x = layer(x)\n","\n","        x = self.layer_norm(x)\n","        logits = self.linear_output(x)\n","\n","        loss = None\n","        if targets is not None:\n","            B, T, C = logits.shape\n","            logits = logits.view(B * T, C)\n","            targets = targets.view(B * T)\n","            loss = F.cross_entropy(logits, targets)\n","        return logits, loss\n","\n","    def generate(self, input_tokens, max_new_tokens, temperature):\n","        self.eval()\n","        for _ in range(max_new_tokens):\n","            cropped = input_tokens[:, -self.config.block_size:]\n","            output, _ = self.forward(cropped, None)\n","            logits = output[:, -1, :] / temperature\n","            probs = F.softmax(logits, dim=-1)\n","            next_token = torch.argmax(probs, dim=-1, keepdim=True)\n","            input_tokens = torch.cat((input_tokens, next_token), dim=1)\n","        return input_tokens\n","\n","\n","class Block(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.attention = MultiHeadAttention(config)\n","        self.mlp = MLP(config)\n","        self.layer_norm_1 = nn.LayerNorm(config.n_embed)\n","        self.layer_norm_2 = nn.LayerNorm(config.n_embed)\n","\n","    def forward(self, x):\n","        x = x + self.attention(self.layer_norm_1(x))\n","        x = x + self.mlp(self.layer_norm_2(x))\n","        return x\n","\n","class MLP(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.l1 = nn.Linear(config.n_embed, config.n_embed * 4)\n","        self.a1 = nn.ReLU()\n","        self.l2 = nn.Linear(config.n_embed * 4, config.n_embed)\n","        self.dropout = nn.Dropout(config.dropout)\n","\n","    def forward(self, x):\n","        x = self.l1(x)\n","        x = self.a1(x)\n","        x = self.l2(x)\n","        x = self.dropout(x)\n","        return x\n","\n","class Head(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.queries = nn.Linear(config.n_embed, config.head_size)\n","        self.keys = nn.Linear(config.n_embed, config.head_size)\n","        self.values = nn.Linear(config.n_embed, config.head_size)\n","        self.dropout = nn.Dropout(config.dropout)\n","\n","        self.register_buffer(\"tril\", torch.tril(torch.ones(config.block_size, config.block_size)).to(device))\n","\n","    def forward(self, x):\n","        B, T, C = x.shape\n","\n","        q = self.queries(x)\n","        k = self.keys(x)\n","        v = self.values(x)\n","\n","        weights = q @ k.transpose(-2, -1) * (k.shape[-1] ** -0.5)\n","        weights = weights.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n","\n","        weights = F.softmax(weights, dim=-1)\n","        weights = self.dropout(weights)\n","\n","        out = weights @ v\n","        return out\n","\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.heads = nn.ModuleList([Head(config) for _ in range(config.n_head)])\n","        self.projection = nn.Linear(config.n_head * config.head_size, config.n_embed)\n","        self.dropout = nn.Dropout(config.dropout)\n","\n","    def forward(self, x):\n","        out = torch.cat([head(x) for head in self.heads], dim=-1)\n","        out = self.projection(out)\n","        out = self.dropout(out)\n","        return out\n"]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","import statistics\n","import math\n","import torch\n","import pickle\n","\n","\"\"\"\n","with open(\"/content/drive/MyDrive/Tiny-Shakespeare/shakespeare-dataset.txt\", \"r\", encoding=\"utf-8\") as f:\n","    text_sequence = f.read()\n","encoded = tokenizer.encode(text_sequence)\n","\"\"\"\n","\n","file_path = '/content/drive/MyDrive/Tiny-Shakespeare/encoded_data.pkl'\n","\n","with open(file_path, 'rb') as f:\n","    encoded = pickle.load(f)\n","\n","val_split = int(len(encoded) * 0.9)\n","train_data = encoded[:val_split]\n","val_data = encoded[val_split:]\n","\n","class ShakespeareDataset(Dataset):\n","    def __init__(self, dataset, config):\n","        self.data = dataset\n","        self.config = config\n","\n","    def __len__(self):\n","        return len(self.data) - self.config.block_size\n","\n","    def __getitem__(self, index):\n","        x = self.data[index:index + self.config.block_size]\n","        y = self.data[index + 1:index + self.config.block_size + 1]\n","        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n","\n","def get_loaders(train_data, val_data, config):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    train_dataset = ShakespeareDataset(train_data, config)\n","    val_dataset = ShakespeareDataset(val_data, config)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)\n","\n","    return train_loader, val_loader\n","\n","def val_loss(model, val_loader, device, max_batches):\n","    model.eval()\n","    loss_list = []\n","\n","    with torch.no_grad():\n","        for i, (batch_x, batch_y) in enumerate(val_loader):\n","            if i >= max_batches:\n","                break\n","            batch_x = batch_x.to(device)\n","            batch_y = batch_y.to(device)\n","            _, loss = model(batch_x, batch_y)\n","            loss_list.append(loss.item())\n","\n","    return statistics.mean(loss_list)\n","\n","def eval_generate(model, tokenizer, device):\n","    model.eval()\n","    input_sequence = \"O gentle night, why dost thou weep so soft upon the silent earth?\"\n","    input_sequence = tokenizer.encode(input_sequence)\n","    tensors = torch.tensor(input_sequence, dtype=torch.long).unsqueeze(0).to(device)\n","\n","    with torch.no_grad():\n","        output = model.generate(tensors, 100)\n","\n","    return tokenizer.decode(output[0].tolist())"],"metadata":{"id":"YHkyUeBnDIz7","executionInfo":{"status":"ok","timestamp":1744900828175,"user_tz":-120,"elapsed":95,"user":{"displayName":"guillem romero","userId":"01648526312521908562"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["import torch\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","epochs = 1\n","batch_per_display = 100\n","batch_per_generation = 300\n","\n","config = Config()\n","train_loader, val_loader = get_loaders(train_data, val_data, config)\n","model = GPT_Model(config).to(device)\n","optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-2)\n","\n","loss_list = []\n","validation_losses = []\n","\n","for epoch in range(epochs):\n","    for batch_idx, (batch_x, batch_y) in enumerate(train_loader):\n","        batch_x = batch_x.to(device)\n","        batch_y = batch_y.to(device)\n","\n","        output, loss = model(batch_x, batch_y)\n","\n","        optimizer.zero_grad(set_to_none=True)\n","        loss.backward()\n","        optimizer.step()\n","\n","        if batch_idx % batch_per_display == 0 or batch_idx == len(train_loader) - 1:\n","            avg_loss = val_loss(model, val_loader, device, 5)\n","            print(f\"Epoch: {epoch} - Batch: {batch_idx} - Train-Loss: {loss.item():.4f} - Val-Loss: {avg_loss:.4f}\")\n","            validation_losses.append(avg_loss)\n","            loss_list.append(loss.item())\n"],"metadata":{"id":"21zm1j1gulzY","colab":{"base_uri":"https://localhost:8080/","height":738},"executionInfo":{"status":"error","timestamp":1744901766287,"user_tz":-120,"elapsed":936334,"user":{"displayName":"guillem romero","userId":"01648526312521908562"}},"outputId":"bb906855-1c7b-4141-e463-c206ffa047c9"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 0 - Batch: 0 - Train-Loss: 7.0902 - Val-Loss: 6.8380\n","Epoch: 0 - Batch: 100 - Train-Loss: 4.7448 - Val-Loss: 4.8472\n","Epoch: 0 - Batch: 200 - Train-Loss: 4.2032 - Val-Loss: 4.5634\n","Epoch: 0 - Batch: 300 - Train-Loss: 4.1472 - Val-Loss: 4.4103\n","Epoch: 0 - Batch: 400 - Train-Loss: 4.0161 - Val-Loss: 4.2261\n","Epoch: 0 - Batch: 500 - Train-Loss: 3.8205 - Val-Loss: 4.0142\n","Epoch: 0 - Batch: 600 - Train-Loss: 3.5332 - Val-Loss: 3.8749\n","Epoch: 0 - Batch: 700 - Train-Loss: 3.3935 - Val-Loss: 3.8189\n","Epoch: 0 - Batch: 800 - Train-Loss: 3.2507 - Val-Loss: 3.7111\n","Epoch: 0 - Batch: 900 - Train-Loss: 2.9192 - Val-Loss: 3.6613\n","Epoch: 0 - Batch: 1000 - Train-Loss: 3.0709 - Val-Loss: 3.5714\n","Epoch: 0 - Batch: 1100 - Train-Loss: 3.0246 - Val-Loss: 3.5588\n","Epoch: 0 - Batch: 1200 - Train-Loss: 2.8410 - Val-Loss: 3.4906\n","Epoch: 0 - Batch: 1300 - Train-Loss: 2.8818 - Val-Loss: 3.4477\n","Epoch: 0 - Batch: 1400 - Train-Loss: 2.6741 - Val-Loss: 3.4512\n","Epoch: 0 - Batch: 1500 - Train-Loss: 2.6766 - Val-Loss: 3.3556\n","Epoch: 0 - Batch: 1600 - Train-Loss: 2.5715 - Val-Loss: 3.4714\n","Epoch: 0 - Batch: 1700 - Train-Loss: 2.4588 - Val-Loss: 3.4530\n","Epoch: 0 - Batch: 1800 - Train-Loss: 2.5293 - Val-Loss: 3.4970\n","Epoch: 0 - Batch: 1900 - Train-Loss: 2.5397 - Val-Loss: 3.4436\n","Epoch: 0 - Batch: 2000 - Train-Loss: 2.4547 - Val-Loss: 3.5641\n","Epoch: 0 - Batch: 2100 - Train-Loss: 2.4327 - Val-Loss: 3.5917\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-66851efedbbb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset_to_none\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["torch.save(model.state_dict(), \"/content/drive/MyDrive/Tiny-Shakespeare/model_parameters.pth\")"],"metadata":{"id":"vULTjZlhRTNv","executionInfo":{"status":"ok","timestamp":1744902111713,"user_tz":-120,"elapsed":485,"user":{"displayName":"guillem romero","userId":"01648526312521908562"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["generator = GPT_Model(Config())\n","\n","generator.load_state_dict(torch.load(\"/content/drive/MyDrive/Tiny-Shakespeare/model_parameters.pth\"))\n","input_tokens = \"When moonlight strikes the ivy'd stone, what secrets wake beneath the throne?\"\n","tokens = tokenizer.encode(input_tokens)\n","tensor = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n","output = generator.generate(tensor, 100, 1.5)\n","print(tokenizer.decode(output[0].tolist()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tVXbAHwfQARH","executionInfo":{"status":"ok","timestamp":1744902949039,"user_tz":-120,"elapsed":7645,"user":{"displayName":"guillem romero","userId":"01648526312521908562"}},"outputId":"bf0db53f-6dea-495b-eba9-894f5ae6d0f8"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["When moonlight strikes the ivy'd stone, what secrets wake beneath the throne?  \n","    O, let me seek the curtains of the axe-day;\n","    and then I see the sun of purposed skulls by\n","    the sun of a double baser and a double black of purd'ring\n","    the sun of a dragon, a dragon, a dragon, a drawer\n"]}]},{"cell_type":"code","source":["import plotly.graph_objects as go\n","\n","fig = go.Figure()\n","fig.add_trace(go.Scatter(y=loss_list, mode='lines', name='Train Losses'))\n","fig.add_trace(go.Scatter(y=validation_losses, mode='lines', name='Val Losses'))\n","fig.update_layout(\n","    title='Loss Training Curve',\n","    xaxis_title='Batch',\n","    yaxis_title='Loss'\n",")\n","fig.show()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"OoFgt-qCVjaP","executionInfo":{"status":"ok","timestamp":1744903226356,"user_tz":-120,"elapsed":458,"user":{"displayName":"guillem romero","userId":"01648526312521908562"}},"outputId":"db0d45e4-fdee-4d22-ea93-ff0c00b023f1"},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e295e930-862d-43d9-9a8c-da8ea21cb8f1\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e295e930-862d-43d9-9a8c-da8ea21cb8f1\")) {                    Plotly.newPlot(                        \"e295e930-862d-43d9-9a8c-da8ea21cb8f1\",                        [{\"mode\":\"lines\",\"name\":\"Train Losses\",\"y\":[7.090170860290527,4.744802951812744,4.203185081481934,4.147190093994141,4.016106128692627,3.8205432891845703,3.5332159996032715,3.3934755325317383,3.250741958618164,2.919236660003662,3.0709221363067627,3.024613380432129,2.841036081314087,2.881781578063965,2.6740763187408447,2.6766011714935303,2.5714776515960693,2.4588112831115723,2.5292530059814453,2.5396597385406494,2.4546680450439453,2.432736873626709],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"Val Losses\",\"y\":[6.8380406379699705,4.847198390960694,4.563353633880615,4.410283851623535,4.226141357421875,4.014173269271851,3.874868297576904,3.818900299072266,3.7110716342926025,3.6612943172454835,3.5713809013366697,3.5588473320007323,3.4906457901000976,3.447661781311035,3.4511658191680907,3.355599117279053,3.4713616371154785,3.4529701232910157,3.4969836711883544,3.4436322689056396,3.564097547531128,3.591711950302124],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Loss Training Curve\"},\"xaxis\":{\"title\":{\"text\":\"Batch\"}},\"yaxis\":{\"title\":{\"text\":\"Loss\"}}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('e295e930-862d-43d9-9a8c-da8ea21cb8f1');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]}]}